#!/usr/bin/env python3
"""
Test AGNO streaming in isolation using the proper AGNO patterns from documentation.
This will help us understand the real-time streaming behavior.
"""

import os
import time
import sys
from datetime import datetime

# Add the app directory to Python path so we can import backend modules
sys.path.insert(0, '/Users/caroco/Gabo-Dev/kiff-ai/backend/app')

# Import AGNO modules
from agno.agent import Agent, RunResponseEvent
from agno.tools.file import FileTools

# Import our backend model configuration
from app.config.llm_providers import get_tradeforge_models

def create_simple_todo_tracker():
    """Create a simple todo tracker for testing"""
    from agno.tools import Toolkit
    from agno import Agent
    
    class SimpleTodoTracker(Toolkit):
        def __init__(self):
            super().__init__(name="simple_todo_tracker")
        
        def track_todo_progress(self, action: str, description: str = "") -> str:
            """Track todo progress with simple console output"""
            timestamp = datetime.now().strftime("%H:%M:%S")
            print(f"ğŸ“‹ [{timestamp}] TODO: {action} - {description}")
            return f"Todo tracked: {action} - {description}"
    
    return SimpleTodoTracker()

def test_agno_streaming():
    """Test AGNO agent with streaming enabled using proper AGNO patterns"""
    print("ğŸ”¥ Testing AGNO Streaming Behavior")
    print("=" * 50)
    
    # Get models from backend configuration (same as backend uses)
    print("ğŸ¤– Loading backend model configuration...")
    try:
        available_models = get_tradeforge_models()
        selected_llm = available_models.get("kimi-k2")  # Use same model as frontend
        print(f"âœ… Using model: kimi-k2")
        
        agent = Agent(
            model=selected_llm,
            tools=[FileTools()],
            show_tool_calls=True,
            instructions=[
                "You are a helpful AI assistant that creates files as requested.",
                "Save files to the /tmp/agno_test/ directory.",  
                "Be conversational and explain what you're doing.",
                "IMPORTANT: When using save_file, use format: save_file(file_name='path/file.ext', contents='your content')"
            ]
        )
        print("âœ… Agent created successfully")
    except Exception as e:
        print(f"âŒ Failed to create agent: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # Simple test prompt
    test_prompt = "Create a simple hello.txt file with 'Hello World' content in /tmp/agno_test/"
    
    print(f"ğŸ“ Test Prompt: {test_prompt}")
    print("\nğŸš€ Starting AGNO agent streaming...")
    print("=" * 50)
    
    # Track streaming behavior
    event_count = 0
    start_time = datetime.now()
    
    try:
        # Use proper AGNO streaming pattern from docs
        response_stream = agent.run(
            test_prompt, 
            stream=True, 
            stream_intermediate_steps=True
        )
        
        print("ğŸ“¡ Stream started, processing events...")
        
        for event in response_stream:
            event_count += 1
            current_time = datetime.now()
            elapsed = (current_time - start_time).total_seconds()
            
            print(f"â° [{elapsed:6.2f}s] Event #{event_count}: {event.event}")
            
            # Handle different event types using proper AGNO patterns
            if event.event == "RunResponseContent":
                if hasattr(event, 'content') and event.content:
                    content_preview = str(event.content)[:50]
                    print(f"   ğŸ“ Content: '{content_preview}'")
                    print("   ğŸ’¬ BACKEND WOULD YIELD: conversation event with this content")
                    
            elif event.event == "ToolCallStarted":
                if hasattr(event, 'tool'):
                    print(f"   ğŸ”§ Tool Started: {event.tool.tool_name}")
                    print(f"   ğŸ“‹ Tool Args: {event.tool.tool_args}")
                    print("   ğŸ’¬ BACKEND WOULD YIELD: conversation event 'Creating file...'")
                
            elif event.event == "ToolCallCompleted":
                if hasattr(event, 'tool'):
                    print(f"   âœ… Tool Completed: {event.tool.tool_name}")
                    print(f"   ğŸ“Š Tool Result: {event.tool.result}")
                    
                    # Extract AGNO metrics from tool execution
                    if hasattr(event.tool, 'metrics') and event.tool.metrics:
                        metrics = event.tool.metrics
                        print(f"   ğŸ“ˆ Tool Metrics:")
                        print(f"      - Input tokens: {getattr(metrics, 'input_tokens', 0)}")
                        print(f"      - Output tokens: {getattr(metrics, 'output_tokens', 0)}")
                        print(f"      - Total tokens: {getattr(metrics, 'total_tokens', 0)}")
                        print(f"      - Execution time: {getattr(metrics, 'time', 0):.3f}s")
                        print(f"      - Cached tokens: {getattr(metrics, 'cached_tokens', 0)}")
                        print(f"      - Reasoning tokens: {getattr(metrics, 'reasoning_tokens', 0)}")
                    
                    print("   ğŸ’¬ BACKEND WOULD YIELD: conversation event 'File created!'")
                    print("   ğŸ“ BACKEND WOULD YIELD: file_created event with file data")
                
            elif event.event == "ReasoningStarted":
                print("   ğŸ§  Reasoning Started")
                print("   ğŸ’¬ BACKEND WOULD YIELD: conversation event 'Analyzing requirements...'")
                
            elif event.event == "ReasoningCompleted":
                print("   ğŸ§  Reasoning Completed") 
                print("   ğŸ’¬ BACKEND WOULD YIELD: conversation event 'Analysis complete. Beginning implementation...'")
                
            elif event.event == "ReasoningStep":
                if hasattr(event, 'content') and event.content:
                    reasoning_preview = str(event.content)[:80]
                    print(f"   ğŸ’­ Reasoning: {reasoning_preview}...")
                    
            elif event.event == "RunStarted":
                print("   ğŸš€ AGNO Run Started")
                print("   ğŸ’¬ BACKEND WOULD YIELD: conversation event 'Starting work on your request...'")
                
            elif event.event == "RunCompleted":
                print("   ğŸ AGNO Run Completed")
                print("   ğŸ’¬ BACKEND WOULD YIELD: conversation event 'Application completed!'")
                
            else:
                print(f"   â“ Other event: {event.event}")
                if hasattr(event, '__dict__'):
                    for key, value in event.__dict__.items():
                        if key not in ['event']:
                            print(f"      {key}: {value}")
            
            print()  # Empty line for readability
            
            # Small delay to observe real-time behavior
            time.sleep(0.02)  # Faster to see real timing
            
    except Exception as e:
        print(f"âŒ Error during streaming: {e}")
        import traceback
        traceback.print_exc()
    
    total_time = (datetime.now() - start_time).total_seconds()
    print("=" * 50)
    print(f"ğŸ Streaming Complete!")
    print(f"   ğŸ“Š Total Events: {event_count}")
    print(f"   â±ï¸  Total Time: {total_time:.2f}s")
    if total_time > 0:
        print(f"   ğŸ“ˆ Events/sec: {event_count/total_time:.2f}")
    
    print("\n" + "=" * 50)
    print("ğŸ“ˆ COMPREHENSIVE AGNO METRICS ANALYSIS")
    print("=" * 50)
    
    # 1. SESSION-LEVEL METRICS (Most Important!)
    print("ğŸ”¥ SESSION METRICS (session_metrics):")
    if hasattr(agent, 'session_metrics') and agent.session_metrics:
        session_metrics = agent.session_metrics
        print(f"   ğŸ“Š Input tokens: {getattr(session_metrics, 'input_tokens', 0)}")
        print(f"   ğŸ“Š Output tokens: {getattr(session_metrics, 'output_tokens', 0)}")
        print(f"   ğŸ“Š Total tokens: {getattr(session_metrics, 'total_tokens', 0)}")
        print(f"   ğŸ“Š Cached tokens: {getattr(session_metrics, 'cached_tokens', 0)}")
        print(f"   ğŸ“Š Reasoning tokens: {getattr(session_metrics, 'reasoning_tokens', 0)}")
        print(f"   ğŸš€ This is what our backend should track for real-time token consumption!")
    else:
        print("   âš ï¸ Session metrics not available")
    
    # 2. RUN RESPONSE METRICS  
    print(f"\nğŸ¯ RUN RESPONSE METRICS (run_response.metrics):")
    if hasattr(agent, 'run_response') and agent.run_response:
        if hasattr(agent.run_response, 'metrics') and agent.run_response.metrics:
            run_metrics = agent.run_response.metrics
            print(f"   ğŸ“Š Input tokens: {getattr(run_metrics, 'input_tokens', 0)}")
            print(f"   ğŸ“Š Output tokens: {getattr(run_metrics, 'output_tokens', 0)}")
            print(f"   ğŸ“Š Total tokens: {getattr(run_metrics, 'total_tokens', 0)}")
            print(f"   â±ï¸ Total time: {getattr(run_metrics, 'time', 0):.3f}s")
            print(f"   âš¡ Time to first token: {getattr(run_metrics, 'time_to_first_token', 0):.3f}s")
        else:
            print("   âš ï¸ Run response metrics not available")
            
        # 3. PER-MESSAGE METRICS
        print(f"\nğŸ’¬ PER-MESSAGE METRICS (run_response.messages):")
        if hasattr(agent.run_response, 'messages'):
            for i, message in enumerate(agent.run_response.messages):
                if hasattr(message, 'metrics') and message.metrics:
                    print(f"   ğŸ“ Message #{i+1} ({message.role}):")
                    print(f"      - Tokens: {getattr(message.metrics, 'total_tokens', 0)}")
                    print(f"      - Time: {getattr(message.metrics, 'time', 0):.3f}s")
                    if hasattr(message, 'content'):
                        content_preview = str(message.content)[:60]
                        print(f"      - Content: '{content_preview}...'")
        else:
            print("   âš ï¸ Messages not available")
    else:
        print("   âš ï¸ Run response not available")
    
    # 4. AVAILABLE ATTRIBUTES (Debug info)
    print(f"\nğŸ” AGENT DEBUG INFO:")
    print(f"   ğŸ¤– Agent attributes: {[attr for attr in dir(agent) if not attr.startswith('_')]}")
    if hasattr(agent, 'run_response'):
        print(f"   ğŸ“‹ RunResponse attributes: {[attr for attr in dir(agent.run_response) if not attr.startswith('_')]}")
    
    # Check if file was actually created
    print(f"\nğŸ“ FILE CREATION VERIFICATION:")
    if os.path.exists('/tmp/agno_test/hello.txt'):
        print(f"   âœ… File created successfully!")
        with open('/tmp/agno_test/hello.txt', 'r') as f:
            print(f"   ğŸ“„ Content: {f.read()}")
    else:
        print(f"   âš ï¸  File not found")
    
    print("\n" + "=" * 50)
    print("ğŸ¯ KEY INSIGHTS FOR BACKEND IMPLEMENTATION:")
    print("=" * 50)
    print("1. ğŸ”¥ Use agent.session_metrics for real-time token tracking")
    print("2. âš¡ Events stream every ~0.02-0.05s - backend should match this")
    print("3. ğŸ› ï¸ ToolCallStarted/Completed events are the key for file creation")
    print("4. ğŸ“ RunResponseContent events should drive conversation messages")
    print("5. ğŸš€ Each event should yield immediately to frontend, not batch")
    print("=" * 50)

if __name__ == "__main__":
    # Create test directory
    os.makedirs('/tmp/agno_test', exist_ok=True)
    
    # Run the test
    test_agno_streaming()