services:
  # Core Backend Service - Lightweight API
  core-backend:
    build:
      context: ./backend-lite-v2
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      - ML_SERVICE_URL=https://7p5dqvvip5.eu-west-3.awsapprunner.com
      - DATABASE_URL=sqlite:///./kiff_dev.db
      - AWS_REGION=eu-west-3
    # depends_on:
      # - ml-service  # Using deployed ML service instead
    volumes:
      - ./backend-lite-v2/kiff_dev.db:/app/kiff_dev.db
    networks:
      - kiff-network

  # ML Service - Heavy AI/ML operations
  ml-service:
    build:
      context: ./ml-service
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
    env_file:
      - .env
    environment:
      - LANCEDB_DIR=/data/vectors
      - TRANSFORMERS_CACHE=/models/hf
      - HF_HOME=/models/hf
      - SENTENCE_TRANSFORMERS_HOME=/models/sentence_transformers
    volumes:
      - ml-models:/models
      - ml-vectors:/data
    networks:
      - kiff-network

  # Frontend (commented out - no Dockerfile yet)
  # frontend:
  #   build:
  #     context: ./frontend-lite
  #     dockerfile: Dockerfile
  #   ports:
  #     - "3000:3000"
  #   environment:
  #     - NEXT_PUBLIC_API_BASE_URL=http://localhost:8000
  #   depends_on:
  #     - core-backend
  #   networks:
  #     - kiff-network

volumes:
  ml-models:
    driver: local
  ml-vectors:
    driver: local

networks:
  kiff-network:
    driver: bridge